# Qwen3-TTS Server Dependencies
# Optimized for CUDA 12.4 / A100 GPU deployment

# Core ML Libraries (CUDA 12.4 compatible)
torch>=2.5.1
torchvision>=0.20.0
torchaudio>=2.5.1
--extra-index-url https://download.pytorch.org/whl/cu124

# Qwen3-TTS and dependencies
qwen-tts>=0.0.4
transformers==4.57.3
accelerate==1.12.0

# Audio processing
soundfile>=0.12.1
numpy>=1.26.4,<2.0.0

# API Server
fastapi==0.128.0
uvicorn[standard]==0.34.2
python-multipart>=0.0.6
pydantic>=2.0.0

# Utilities
python-dotenv

# Optional: Flash Attention 2 (Linux only, install separately)
# Significantly improves inference speed on A100
# pip install -U flash-attn --no-build-isolation
