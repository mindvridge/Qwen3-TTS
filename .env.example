# Qwen3-TTS Server Configuration
# Copy this file to .env and modify as needed

# Server Settings
TTS_HOST=0.0.0.0
TTS_PORT=8000

# Device Configuration
TTS_DEVICE=cuda:0
TTS_DTYPE=bfloat16

# Performance Settings
# Flash Attention 2 (Linux + A100/H100 only, 2-3x speedup)
# Set to true on A100 GPU with Linux (Elice Cloud, RunPod, etc.)
# Set to false on Windows or older GPUs
TTS_USE_FLASH_ATTENTION=true

# torch.compile (PyTorch 2.0+, experimental)
# May cause CUDA errors on some setups, test before enabling in production
# Recommended: false (stable), true (if you want to experiment)
TTS_USE_TORCH_COMPILE=false

# Warmup (first inference optimization)
# Only useful with torch.compile enabled
# Recommended: false (disabled by default)
TTS_USE_WARMUP=false

# Default Model
# Options: base_0.6b, base_1.7b
TTS_DEFAULT_MODEL=base_0.6b

# Model Paths (optional - auto-download from Hugging Face if not set)
# Uncomment and set path only if you have local model files
# MODEL_0_6B_BASE=/path/to/Qwen3-TTS-12Hz-0.6B-Base
# MODEL_1_7B_BASE=/path/to/Qwen3-TTS-12Hz-1.7B-Base

# Video Generation (Optional)
# Set to true to enable TTS + Lip-sync video generation with MuseTalk
ENABLE_VIDEO=false
# Path to directory containing MuseTalk (git clone https://github.com/TMElyralab/MuseTalk.git NewAvata/MuseTalk)
NEWAVATA_PATH=NewAvata
# Directory for avatar images (JPG/PNG files)
VIDEO_AVATAR_DIR=avatars
# Directory for output videos
VIDEO_OUTPUT_DIR=output

# ============================================================
# Recommended Configurations by Deployment Environment
# ============================================================

# 1. Local Development (Windows, RTX 4070 Ti / RTX 3060)
#    TTS_USE_FLASH_ATTENTION=false (not supported on Windows)
#    TTS_USE_TORCH_COMPILE=false
#    TTS_DEFAULT_MODEL=base_0.6b
#    ENABLE_VIDEO=false

# 2. Elice Cloud A100 40GB (TTS only)
#    TTS_USE_FLASH_ATTENTION=true (2-3x speedup)
#    TTS_USE_TORCH_COMPILE=false (stable)
#    TTS_DTYPE=bfloat16 (A100 optimized)
#    TTS_DEFAULT_MODEL=base_0.6b (8GB VRAM)
#    ENABLE_VIDEO=false

# 3. Elice Cloud A100 80GB (TTS + Video)
#    TTS_USE_FLASH_ATTENTION=true
#    TTS_USE_TORCH_COMPILE=false
#    TTS_DTYPE=bfloat16
#    TTS_DEFAULT_MODEL=base_0.6b (memory efficient)
#    ENABLE_VIDEO=true (requires ~25GB VRAM total)

# 4. RunPod / Vast.ai (Docker deployment)
#    Same as Elice Cloud settings
#    Use docker-compose.yml (TTS only) or docker-compose.video.yml (TTS+Video)
